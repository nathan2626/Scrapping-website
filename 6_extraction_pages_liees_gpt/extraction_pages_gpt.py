import json
import os
import time
import re
import pymupdf as fitz  # PyMuPDF
import docx
import pptx
from openai import OpenAI

# ===========================
# üìÇ Chemins et Param√®tres
# ===========================
INPUT_DIR = "5_scraping_pages_liees"
OUTPUT_DIR = "6_extraction_pages_gpt"
LOG_FILE = os.path.join(OUTPUT_DIR, "gpt_pages_errors.log")
MAX_CONTENT = 10000

# Mots-cl√©s pour filtrer uniquement les pages pertinentes
MOTS_CLES = [
    "congre", "congres", "congress", "congresse", "congresses",
    "2025", "2026", "2027", "event", "events", "planning"
]

# ===========================
# üí¨ Initialisation GPT
# ===========================
with open('key.txt', 'r') as file:
    secret_key = file.read().strip()

client = OpenAI(api_key=secret_key)

# ===========================
# üìù Gestion des logs
# ===========================
def log_erreur(message):
    """Enregistre une erreur dans le fichier de log."""
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"{message}\n")
    print(f"‚ùå {message}")

# ===========================
# üìÇ Filtrage des pages par mots-cl√©s
# ===========================
def contient_mot_cle(texte):
    """V√©rifie si une cha√Æne contient un mot-cl√© pertinent."""
    if not texte:
        return False
    texte = texte.lower()
    return any(mot in texte for mot in MOTS_CLES)

# ===========================
# üìñ Lecture des fichiers t√©l√©charg√©s
# ===========================
def lire_fichier(filepath):
    """Lit le contenu d‚Äôun fichier selon son type."""
    if filepath.endswith(".pdf"):
        return lire_pdf(filepath)
    elif filepath.endswith(".docx"):
        return lire_docx(filepath)
    elif filepath.endswith(".pptx"):
        return lire_pptx(filepath)
    return ""

def lire_pdf(filepath):
    """Lit le contenu d‚Äôun fichier PDF."""
    try:
        doc = fitz.open(filepath)
        return "\n".join([page.get_text() for page in doc])
    except Exception as e:
        log_erreur(f"Erreur lecture PDF {filepath}: {e}")
        return ""

def lire_docx(filepath):
    """Lit le contenu d‚Äôun fichier DOCX."""
    try:
        doc = docx.Document(filepath)
        return "\n".join([p.text for p in doc.paragraphs])
    except Exception as e:
        log_erreur(f"Erreur lecture DOCX {filepath}: {e}")
        return ""

def lire_pptx(filepath):
    """Lit le contenu d‚Äôun fichier PPTX."""
    try:
        presentation = pptx.Presentation(filepath)
        texte = ""
        for slide in presentation.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    texte += shape.text + "\n"
        return texte
    except Exception as e:
        log_erreur(f"Erreur lecture PPTX {filepath}: {e}")
        return ""

# ===========================
# üí¨ Analyse du contenu avec GPT
# ===========================
def analyser_contenu_avec_gpt(url, contenu):
    """Envoie le contenu √† GPT pour analyse et retourne un JSON structur√©."""
    prompt = f"""
    Voici un extrait d'une page web issue de {url}. Analyse-le et retourne **uniquement** un JSON valide en fran√ßais, contenant :

    {{
        "contacts": [
            {{
                "type": "email",
                "valeur": "email@example.com",
                "propri√©taire": {{
                    "nom": "Dr Jean Dupont",
                    "fonction": "Conf√©rencier",
                    "affiliation": "Universit√© de Paris"
                }}
            }},
            {{
                "type": "t√©l√©phone",
                "valeur": "+33 1 23 45 67 89",
                "propri√©taire": {{
                    "nom": "Universit√© de Paris",
                    "type": "Organisation"
                }}
            }},
            {{
                "type": "site_web",
                "valeur": "https://congres2025.fr",
                "propri√©taire": {{
                    "nom": "Organisateur Congr√®s 2025"
                }}
            }}
        ],
        "personnes": [
            {{
                "nom": "Dr Jean Dupont",
                "titre": "Professeur",
                "affiliation": "Universit√© de Paris",
                "contact_email": "jean.dupont@example.com",
                "contact_t√©l√©phone": "+33 1 23 45 67 89",
                "r√¥le": "Conf√©rencier principal",
                "publications": [
                    "√âtude sur l'IA m√©dicale (2023)",
                    "Article dans ScienceDirect (2024)"
                ]
            }},
            {{
                "nom": "Marie Curie",
                "titre": "Chercheuse",
                "affiliation": "Institut Curie",
                "r√¥le": "Intervenante"
            }}
        ],
        "organisateurs": [
            {{
                "nom": "Soci√©t√© Fran√ßaise de M√©decine",
                "type": "Association",
                "site_web": "https://sfmed.fr",
                "email_contact": "contact@sfmed.fr"
            }}
        ],
        "lieux": [
            {{
                "nom": "Centre des Congr√®s de Paris",
                "adresse": "Place de la R√©publique, 75003 Paris",
                "pays": "France"
            }}
        ],
        "dates": [
            {{
                "date_d√©but": "2025-03-10",
                "date_fin": "2025-03-12",
                "√©v√©nement": "Congr√®s International de M√©decine",
                "personnes_associ√©es": ["Dr Jean Dupont", "Marie Curie"],
                "programme": [
                    {{"heure": "09:00", "session": "Ouverture"}},
                    {{"heure": "14:00", "session": "Table ronde IA & Sant√©"}}
                ]
            }}
        ],
        "documents": [
            {{
                "type": "programme",
                "url": "https://congres2025.fr/programme.pdf"
            }},
            {{
                "type": "actes",
                "url": "https://congres2025.fr/actes.pdf"
            }}
        ],
        "r√©seaux_sociaux": [
            {{
                "plateforme": "Twitter",
                "lien": "https://twitter.com/congres2025"
            }},
            {{
                "plateforme": "LinkedIn",
                "lien": "https://linkedin.com/company/congres2025"
            }}
        ],
        "r√©sum√©": "Le Congr√®s International de M√©decine 2025 se tiendra √† Paris et abordera les avanc√©es m√©dicales avec des conf√©rences d‚Äôexperts et des tables rondes sur l‚ÄôIA en sant√©."
    }}

    Extrait :
    {contenu[:MAX_CONTENT]}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        resultat = response.choices[0].message.content.strip()

        if resultat.startswith("{") and resultat.endswith("}"):
            return json.loads(resultat)
        else:
            log_erreur(f"Erreur JSON GPT sur {url} : {resultat[:500]}")
            return {"erreur": "R√©ponse non JSON", "contenu_brut": resultat}

    except Exception as e:
        log_erreur(f"Erreur GPT sur {url}: {e}")
        return {"erreur": str(e)}

# ===========================
# üíæ Fonction principale
# ===========================
def analyser_toutes_pages():
    """Parcourt toutes les pages et fichiers t√©l√©charg√©s et lance l'analyse GPT."""
    for domaine in os.listdir(INPUT_DIR):
        domaine_path = os.path.join(INPUT_DIR, domaine)
        if not os.path.isdir(domaine_path):
            continue

        print(f"\nüöÄ Analyse GPT pour le domaine : {domaine}")
        analyses = []

        # ===========================
        # üìñ Analyse des Pages HTML
        # ===========================
        pages_dir = os.path.join(domaine_path, "pages_html")
        if os.path.exists(pages_dir):
            for page_file in os.listdir(pages_dir):
                with open(os.path.join(pages_dir, page_file), "r", encoding="utf-8") as f:
                    contenu = f.read()

                # Filtrage par mots-cl√©s
                if not contient_mot_cle(contenu) and not contient_mot_cle(page_file):
                    print(f"üö´ Ignor√© (page non pertinente) : {page_file}")
                    continue

                print(f"üí¨ Analyse GPT de la page : {page_file}")
                resultat = analyser_contenu_avec_gpt(page_file, contenu)
                analyses.append({
                    "type": "page_html",
                    "nom": page_file,
                    "contenu": contenu[:500],
                    "analyse": resultat
                })

        # ===========================
        # üìÇ Analyse des Fichiers T√©l√©charg√©s
        # ===========================
        fichiers_dir = os.path.join(domaine_path, "fichiers")
        if os.path.exists(fichiers_dir):
            for fichier in os.listdir(fichiers_dir):
                # Exclure les images
                if re.search(r"\.(jpg|jpeg|png|gif|svg|webp)$", fichier, re.IGNORECASE):
                    print(f"üö´ Ignor√© (image) : {fichier}")
                    continue

                contenu = lire_fichier(os.path.join(fichiers_dir, fichier))

                # Filtrage par mots-cl√©s
                if not contient_mot_cle(contenu) and not contient_mot_cle(fichier):
                    print(f"üö´ Ignor√© (fichier non pertinent) : {fichier}")
                    continue

                print(f"üí¨ Analyse GPT du fichier : {fichier}")
                resultat = analyser_contenu_avec_gpt(fichier, contenu)
                analyses.append({
                    "type": "fichier",
                    "nom": fichier,
                    "contenu": contenu[:500],
                    "analyse": resultat
                })

        # ===========================
        # üíæ Enregistrement des R√©sultats
        # ===========================
        output_domaine = os.path.join(OUTPUT_DIR, domaine)
        os.makedirs(output_domaine, exist_ok=True)
        output_file = os.path.join(output_domaine, f"{domaine}_analyses_gpt.json")

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(analyses, f, indent=4, ensure_ascii=False)

        print(f"‚úÖ Analyse GPT termin√©e pour {domaine}. R√©sultats dans {output_file}")

# ===========================
# ‚ñ∂Ô∏è Ex√©cution
# ===========================
if __name__ == "__main__":
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    analyser_toutes_pages()
